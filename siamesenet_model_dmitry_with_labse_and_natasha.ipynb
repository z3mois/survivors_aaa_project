{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdmV905Pd13T"
   },
   "source": [
    "# 0. Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SXe-ZqmPTZmR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from razdel import tokenize, sentenize\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWbmn4YXdue0"
   },
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3ekrbaFTW8F",
    "outputId": "56ffb31a-ada4-46d6-b6f4-77c401dbb8f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.5668e-01, -7.9142e-01, -5.0812e-01, -9.8696e-01,  6.6171e-02,\n",
       "        -5.4171e-01,  4.5069e-01, -8.2792e-01, -9.8220e-01, -8.5164e-01,\n",
       "         7.3792e-01, -7.0949e-01,  2.1814e-01, -6.0538e-01, -1.0774e-01,\n",
       "        -9.6845e-01, -6.5996e-01, -2.1084e-02,  1.0497e-01, -3.8302e-01,\n",
       "        -4.3587e-02, -9.6350e-01, -4.4819e-01, -7.4100e-01, -9.3513e-01,\n",
       "        -9.3505e-02, -2.7327e-01,  3.2618e-01,  1.6681e-01, -2.8431e-01,\n",
       "        -9.8772e-01, -4.3425e-01, -2.5844e-02, -4.6207e-01, -4.5117e-01,\n",
       "        -4.7463e-01,  6.1623e-01, -7.2307e-01, -7.8088e-01,  3.3429e-01,\n",
       "        -5.6118e-01, -6.7522e-01, -6.9028e-01, -9.4665e-01, -2.4793e-01,\n",
       "         4.7554e-02,  2.7928e-01, -8.6677e-01, -6.4995e-01, -9.7788e-01,\n",
       "        -9.7562e-01, -9.5297e-01, -6.8018e-01, -8.8297e-01, -2.2271e-02,\n",
       "        -4.9821e-01, -4.4296e-01, -3.7419e-01, -6.6041e-01, -1.8406e-02,\n",
       "        -7.3359e-01, -4.5413e-01,  5.1767e-01,  3.5751e-01, -9.8970e-02,\n",
       "        -8.5916e-01, -3.0190e-01, -3.1376e-01, -7.9168e-01, -2.4629e-01,\n",
       "        -4.0958e-02, -7.0311e-01, -7.9655e-01,  3.0616e-03, -9.2024e-01,\n",
       "        -2.4225e-01,  1.1105e-01, -7.2233e-01, -4.1034e-01,  1.5702e-01,\n",
       "         5.8236e-01,  5.6806e-01, -1.4475e-01, -7.9121e-01, -2.9531e-01,\n",
       "        -9.0245e-01, -5.2199e-01, -6.4440e-01, -8.2653e-01, -1.0266e-02,\n",
       "         4.7401e-01, -4.0383e-01, -3.8767e-01,  6.7634e-01, -8.9772e-01,\n",
       "        -4.3227e-01, -4.7138e-01, -7.5043e-01, -6.2030e-01, -9.3324e-02,\n",
       "        -5.1876e-01, -9.5459e-01, -8.5103e-02, -9.5505e-01, -7.6311e-01,\n",
       "        -8.3503e-01,  4.4994e-01, -7.9542e-01, -7.7145e-01,  2.7061e-02,\n",
       "         3.6984e-01, -8.9033e-01, -2.5332e-01, -5.4517e-01,  7.5821e-02,\n",
       "        -2.5997e-01, -6.3616e-01, -9.0493e-01, -9.2091e-01, -8.1368e-01,\n",
       "        -7.4341e-01, -8.7570e-01, -8.8043e-01, -4.3757e-01, -4.4858e-01,\n",
       "        -5.5280e-01, -3.9345e-01,  3.2670e-01, -5.7240e-02, -8.9843e-01,\n",
       "        -7.3395e-01,  7.8984e-02, -7.5524e-01,  1.1006e-01,  5.3498e-01,\n",
       "        -1.2954e-01, -9.3056e-01, -6.9564e-01, -4.2419e-01, -2.4527e-01,\n",
       "        -5.7155e-01, -7.5722e-01, -7.2098e-01, -6.8199e-01, -3.1577e-02,\n",
       "        -9.1789e-02, -3.9809e-01, -8.5932e-01,  2.4780e-01, -3.5145e-01,\n",
       "        -5.7312e-01, -8.8982e-01,  4.8459e-01, -6.8913e-01, -2.8237e-01,\n",
       "        -4.2715e-01,  6.8407e-01, -8.5251e-01,  2.3628e-01, -5.3701e-01,\n",
       "        -8.3776e-02, -3.3012e-01, -8.7525e-01, -2.6654e-01, -4.8782e-01,\n",
       "        -3.5841e-01, -5.7935e-01, -2.8913e-01, -3.2344e-01, -5.6989e-01,\n",
       "         7.6194e-01, -1.0536e-01,  2.0004e-01, -9.9390e-01, -7.7924e-01,\n",
       "        -3.6448e-01,  2.5322e-01,  6.9374e-02,  3.6695e-02, -7.2165e-01,\n",
       "        -9.4144e-01, -5.1365e-01, -4.0482e-01, -1.1502e-01, -9.4147e-01,\n",
       "         1.8145e-02, -4.9200e-01,  8.7206e-01,  4.8907e-01,  7.1232e-01,\n",
       "        -2.5730e-01, -5.6832e-01, -3.6548e-01, -9.5257e-01, -6.8079e-01,\n",
       "        -2.5829e-01,  4.4977e-01, -6.8772e-01, -6.5221e-01,  2.9870e-01,\n",
       "        -1.6014e-01, -3.6344e-01, -2.5967e-01,  5.9349e-01, -4.0425e-01,\n",
       "         6.4002e-01,  6.8953e-01, -9.7244e-01,  7.1546e-01, -4.9767e-02,\n",
       "        -8.1083e-01, -8.2380e-01, -7.7145e-01, -9.2082e-01, -8.5100e-03,\n",
       "         4.0519e-03, -9.9973e-01,  5.9596e-01,  1.8007e-01, -3.1550e-01,\n",
       "         3.9125e-01, -1.1770e-01, -6.7292e-01,  2.7651e-01,  6.7470e-01,\n",
       "        -7.6601e-01,  3.0246e-02,  2.2834e-01,  3.7128e-01, -5.1424e-01,\n",
       "        -9.0372e-01, -9.6306e-01, -4.8118e-01, -9.5082e-01,  2.6894e-01,\n",
       "         3.4296e-01, -1.9945e-01,  3.0054e-01,  3.7081e-01,  1.3030e-01,\n",
       "        -6.9362e-01, -5.3752e-01, -1.0401e-01, -3.5959e-01, -4.7150e-01,\n",
       "        -8.5334e-01, -7.2124e-01, -5.8219e-01, -9.5847e-01, -5.5847e-01,\n",
       "        -8.5299e-01, -9.3424e-01, -8.7335e-01,  6.7367e-01, -9.4011e-01,\n",
       "        -6.3941e-01, -6.7836e-01, -2.5222e-01, -6.1689e-01, -7.8481e-01,\n",
       "        -3.5968e-01, -9.1383e-01, -4.1478e-01,  5.9435e-01, -8.4301e-01,\n",
       "        -3.3886e-02, -1.8350e-01, -3.0821e-01, -3.3997e-01, -5.0812e-01,\n",
       "        -2.7235e-01, -3.8410e-01,  7.0863e-01, -5.6440e-01, -5.3370e-02,\n",
       "        -8.0215e-01, -3.1684e-01, -4.6598e-01, -8.8268e-01, -1.2994e-01,\n",
       "        -8.4062e-01,  7.5485e-02, -6.5714e-01, -6.9421e-01, -6.9589e-01,\n",
       "         1.5215e-02,  4.0001e-02, -8.4041e-01, -8.1841e-01, -6.6438e-01,\n",
       "        -8.7474e-01, -9.4513e-01, -4.4941e-01, -9.8862e-01, -4.5308e-01,\n",
       "        -6.5568e-01, -8.2789e-01,  4.9893e-01, -6.4799e-01, -7.6815e-01,\n",
       "        -3.0091e-01, -6.6127e-01, -6.9340e-01,  2.3638e-02, -3.9287e-01,\n",
       "        -2.9162e-01,  4.4851e-01, -9.9438e-01, -7.2782e-01, -7.5743e-01,\n",
       "        -6.9303e-01, -9.0215e-01, -5.1205e-03,  5.3388e-01,  5.9162e-01,\n",
       "        -4.6135e-02, -7.6032e-01,  2.1516e-01,  1.9324e-01,  4.1581e-01,\n",
       "        -7.2773e-01, -7.8755e-01,  1.6704e-01, -6.7015e-01,  8.4987e-01,\n",
       "        -4.1760e-01, -5.0162e-01, -5.5553e-01, -7.4630e-01, -6.6325e-01,\n",
       "        -2.4441e-01,  1.3194e-02,  9.2033e-01, -9.5179e-01, -7.5130e-01,\n",
       "         4.9993e-01, -2.6574e-01, -6.6692e-01, -7.8413e-01, -2.8786e-01,\n",
       "         6.3228e-01, -3.6836e-01, -1.8165e-01, -6.6938e-01,  4.6320e-01,\n",
       "        -1.5908e-01, -1.0938e-01, -7.7045e-01,  3.1890e-01, -4.8804e-01,\n",
       "        -5.3987e-01, -6.5893e-01, -8.5143e-01, -3.5533e-01, -5.7770e-01,\n",
       "         1.2763e-01, -4.6088e-01, -9.8261e-01, -4.6028e-01,  4.1343e-01,\n",
       "        -9.5236e-01, -2.0094e-01, -9.4255e-01, -9.5917e-01, -8.0666e-01,\n",
       "        -5.4739e-01, -3.9882e-01,  1.4184e-01,  9.6711e-03, -1.4383e-01,\n",
       "        -8.0956e-01, -1.7403e-01, -4.8055e-03, -1.7434e-01, -5.6884e-01,\n",
       "        -9.7364e-01,  2.2127e-01,  2.1719e-01, -8.4620e-01,  2.1181e-01,\n",
       "        -9.9489e-01, -7.3775e-01, -9.2707e-01,  4.3355e-02, -8.7791e-01,\n",
       "        -9.1601e-01, -7.8634e-01, -9.4301e-01,  6.8630e-02, -8.9892e-01,\n",
       "        -2.3831e-01, -8.2462e-01, -1.2469e-01,  4.3020e-01,  6.1061e-01,\n",
       "        -4.5544e-01, -5.5540e-01,  2.4741e-01, -1.0431e-02, -9.6490e-01,\n",
       "        -3.7443e-01, -9.7725e-01, -1.5109e-01, -2.5328e-01,  2.2308e-01,\n",
       "        -8.8465e-01,  2.8645e-01, -4.3017e-01, -6.3200e-01, -9.6760e-01,\n",
       "         3.7566e-01,  6.5290e-02,  3.2839e-01, -7.4391e-01,  2.1545e-01,\n",
       "        -3.1993e-01, -7.3397e-01, -4.8238e-01, -6.2419e-01, -4.2013e-02,\n",
       "        -9.9091e-01, -1.2362e-01,  1.9111e-01,  8.1129e-01, -9.5195e-01,\n",
       "        -7.8357e-01, -1.2290e-02, -9.5891e-01, -7.2360e-01, -4.3323e-01,\n",
       "        -4.2327e-01, -7.3684e-01, -1.0321e-01, -9.4736e-01, -5.9338e-01,\n",
       "         2.5170e-01, -6.0753e-01, -1.3190e-01, -9.8061e-01, -9.7032e-01,\n",
       "        -3.2857e-01, -3.0742e-01, -9.0128e-01,  2.9777e-02, -5.0398e-01,\n",
       "         3.0947e-01, -9.0911e-01, -7.8457e-01, -9.7478e-01, -3.9819e-01,\n",
       "         2.9996e-01, -8.7245e-01, -7.9200e-02, -4.8378e-01, -6.4380e-01,\n",
       "        -3.6291e-03, -5.0427e-01, -1.4380e-01, -7.7079e-01, -6.5579e-01,\n",
       "        -9.2978e-01, -7.3662e-02, -8.0751e-01, -1.6121e-01,  2.5549e-01,\n",
       "        -4.9233e-01, -8.8614e-01,  4.1628e-01,  5.7908e-01, -1.4375e-01,\n",
       "        -5.5039e-01, -6.3593e-01, -8.0358e-01, -9.0681e-01, -7.1765e-01,\n",
       "        -6.9673e-01,  1.7015e-01, -6.8527e-04, -9.9853e-01, -9.8824e-01,\n",
       "        -1.8905e-01, -9.5162e-01,  2.8525e-02, -4.0094e-01, -6.1578e-01,\n",
       "        -9.6972e-01, -8.8449e-02, -2.6655e-01, -7.3460e-01, -5.7792e-01,\n",
       "        -3.9225e-01, -1.0367e-01, -9.8191e-01,  2.0662e-01, -6.7503e-02,\n",
       "        -4.9347e-01, -8.5931e-01, -5.5670e-01, -9.9320e-01, -6.3040e-01,\n",
       "         8.0572e-01, -4.8887e-02, -8.3980e-01, -4.6828e-01,  1.2296e-01,\n",
       "         3.6369e-01, -6.8198e-01, -1.0957e-01, -9.4066e-01, -8.3947e-01,\n",
       "        -4.2395e-01,  5.3822e-01, -8.6488e-01, -1.2269e-01,  1.8329e-01,\n",
       "        -8.4210e-01, -4.2012e-02, -9.8535e-01, -8.8204e-01, -9.1536e-01,\n",
       "        -3.8208e-01,  3.4544e-01,  3.7160e-01, -8.8310e-01, -1.5588e-01,\n",
       "        -5.8301e-01,  3.4383e-01,  9.0902e-03,  5.5304e-01,  4.5131e-01,\n",
       "         7.6584e-01, -7.5963e-01, -3.6267e-02, -6.4813e-01, -7.3723e-01,\n",
       "         1.2342e-01, -5.6897e-01, -9.3453e-01,  2.4186e-01,  5.4151e-02,\n",
       "        -5.1677e-01,  1.2432e-01,  2.8933e-01, -8.0856e-01, -3.7296e-01,\n",
       "        -3.9304e-01, -6.8200e-01, -3.7719e-02, -4.5407e-01, -2.9910e-01,\n",
       "        -6.9715e-01,  5.9677e-01, -3.4157e-01, -4.1500e-01, -3.2897e-02,\n",
       "        -7.8719e-01, -8.9580e-01, -7.6855e-01, -7.9583e-01,  2.3606e-01,\n",
       "        -4.0521e-01, -2.5119e-01, -3.6514e-01,  6.9980e-02, -8.0657e-01,\n",
       "        -3.7350e-01, -7.8980e-01, -5.5014e-01, -1.4365e-01,  7.6387e-01,\n",
       "        -1.4987e-01, -2.0527e-01, -1.9443e-01, -1.6225e-01, -9.1344e-01,\n",
       "         7.6557e-01,  6.9554e-01, -7.7298e-01, -9.1329e-01,  5.0021e-02,\n",
       "         1.9048e-02, -2.0993e-01, -2.3458e-01,  4.1066e-02, -7.8413e-01,\n",
       "        -7.5438e-01, -8.4177e-01,  6.5909e-01, -7.6041e-01,  4.5475e-01,\n",
       "        -7.9654e-01, -7.9917e-01, -1.5564e-01, -9.1718e-01, -6.2336e-01,\n",
       "        -3.7606e-01,  3.8166e-02, -1.7973e-01, -6.6255e-01, -5.4055e-01,\n",
       "        -8.2732e-01, -5.7525e-01, -6.8136e-01, -1.9556e-01,  2.6732e-01,\n",
       "        -6.1945e-01,  4.2920e-01,  2.2084e-01, -2.2438e-01,  5.7485e-02,\n",
       "         3.6463e-01, -3.9508e-01, -1.5926e-01, -8.8962e-01, -7.4873e-01,\n",
       "        -7.4495e-01,  1.3615e-01, -8.4108e-01, -7.4391e-01,  7.5981e-01,\n",
       "        -6.5382e-01, -8.9861e-01, -7.1945e-01,  8.8497e-02, -8.3451e-04,\n",
       "        -5.6935e-01, -8.7252e-01, -7.9525e-01, -6.5970e-01, -7.2732e-01,\n",
       "         6.5630e-01, -4.3918e-01, -5.8189e-01, -2.8118e-01, -3.8929e-01,\n",
       "         6.6336e-02, -1.5027e-01, -5.3300e-01,  6.9814e-01, -4.2210e-01,\n",
       "        -8.4457e-01, -5.4229e-01, -9.2913e-01, -3.5593e-01, -9.7946e-01,\n",
       "         4.8343e-01, -1.6235e-01,  2.9080e-01,  2.1274e-01, -5.3121e-01,\n",
       "        -8.0320e-01, -5.1270e-01,  7.3915e-02, -8.8168e-01,  1.4646e-01,\n",
       "        -3.0178e-01, -7.8474e-01, -4.9070e-01, -7.0471e-01,  5.6749e-01,\n",
       "        -8.6995e-01, -7.0254e-02, -9.0078e-01, -8.5961e-01, -3.5566e-01,\n",
       "        -7.5977e-01, -9.3530e-01, -3.2550e-01,  2.5993e-01,  3.8674e-02,\n",
       "        -7.5178e-02, -8.9862e-01, -6.1362e-01,  5.6212e-01,  2.9765e-01,\n",
       "         2.8161e-01,  6.2336e-01, -6.4909e-01, -3.4658e-01, -5.5058e-01,\n",
       "        -3.1406e-01,  1.7340e-01, -9.3702e-01, -9.3862e-01, -5.2094e-01,\n",
       "         7.5121e-02, -9.3016e-01, -6.1835e-03, -8.8160e-01, -7.8039e-01,\n",
       "         5.3652e-01, -9.5987e-01,  1.2550e-01,  6.7636e-01, -7.1022e-01,\n",
       "         1.3191e-01, -6.5500e-01,  8.7245e-02,  1.1710e-01, -9.0275e-01,\n",
       "        -1.0766e-01, -6.3274e-01, -1.2194e-01,  1.9042e-01, -6.4421e-01,\n",
       "        -5.1677e-01, -3.1483e-01, -9.5827e-01, -9.4913e-01, -7.9636e-01,\n",
       "        -2.4406e-01, -2.4239e-01, -4.6148e-01, -4.6856e-01, -9.9768e-02,\n",
       "         1.0210e-01,  1.5149e-01,  5.0734e-01, -7.8734e-01, -7.8217e-01,\n",
       "         6.9013e-02, -9.0393e-01,  1.7578e-01,  2.7703e-01,  5.8630e-01,\n",
       "         3.9574e-01, -5.6581e-01,  1.3608e-01,  2.2050e-01,  3.3425e-01,\n",
       "         6.6203e-01, -3.3429e-01, -3.7390e-02, -8.9358e-01, -1.5202e-01,\n",
       "        -7.7273e-01, -7.4660e-01, -8.1289e-01, -6.7079e-01, -5.8435e-01,\n",
       "        -4.2591e-01, -2.0343e-01, -8.6649e-01, -3.2641e-01, -2.4788e-01,\n",
       "        -9.0448e-01, -5.9877e-01, -7.8184e-01, -9.4107e-01, -5.4957e-01,\n",
       "         8.3510e-01,  8.3668e-02, -9.0779e-01, -3.1164e-01, -2.7743e-02,\n",
       "        -7.7203e-01, -4.7764e-01, -6.5005e-01,  1.1470e-01, -5.6275e-02,\n",
       "        -7.6311e-01, -4.1856e-01, -8.8937e-01,  1.4212e-01, -2.7056e-01,\n",
       "        -2.0975e-01, -9.9034e-01,  4.0526e-01])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SentenceBertTransformer:\n",
    "    def __init__(self, model_name='setu4993/LaBSE', device='cpu', max_len=512):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def load_model(self):\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model = self.model.eval()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        \n",
    "    def transform(self, text):\n",
    "        inputs = self.tokenizer(\n",
    "            [text], return_tensors=\"pt\", padding=True, max_length=self.max_len, verbose=False, truncation=True\n",
    "        )\n",
    "        inputs = inputs.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            \n",
    "        return outputs[1][0].detach().cpu()\n",
    "tf = SentenceBertTransformer(device=\"cuda\")\n",
    "tf.load_model()\n",
    "tf.transform(\"i go home\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TP1YyznlTdU0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Item_id</th>\n",
       "      <th>EventDate</th>\n",
       "      <th>last_resume_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>Region</th>\n",
       "      <th>City</th>\n",
       "      <th>session_hash</th>\n",
       "      <th>microcat_name</th>\n",
       "      <th>Platform_id</th>\n",
       "      <th>res_title</th>\n",
       "      <th>res_des</th>\n",
       "      <th>vac_title</th>\n",
       "      <th>vac_des</th>\n",
       "      <th>label</th>\n",
       "      <th>rank</th>\n",
       "      <th>max_rank</th>\n",
       "      <th>vac_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.030430e+12</td>\n",
       "      <td>1.353529e+12</td>\n",
       "      <td>2023-03-13 11:21:22</td>\n",
       "      <td>1.427381e+12</td>\n",
       "      <td>Пользовательские события / Объявления / Просмо...</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Москва</td>\n",
       "      <td>8.753473e+18</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Подработка</td>\n",
       "      <td>Бригадир раздачи газет на ж/ д станциях, интер...</td>\n",
       "      <td>Диспетчер оператор (менеджер)</td>\n",
       "      <td>! ! ! ВНИМАНИЕ ! ! ! ОЧЕНЬ ВАЖНО ! ! ! требуют...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.000233e+11</td>\n",
       "      <td>1.237305e+12</td>\n",
       "      <td>2023-03-13 03:02:08</td>\n",
       "      <td>1.401474e+12</td>\n",
       "      <td>Чат / События полученные через AMQP / Отправка...</td>\n",
       "      <td>Иркутская область</td>\n",
       "      <td>Братск</td>\n",
       "      <td>8.963607e+18</td>\n",
       "      <td>Сменный график</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Не имеет значения</td>\n",
       "      <td>Срочно нужна работа !!!</td>\n",
       "      <td>Сборщики в магазин</td>\n",
       "      <td>! В гипермаркет требуются сборщики заказов.\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.073960e+12</td>\n",
       "      <td>1.237305e+12</td>\n",
       "      <td>2023-03-13 13:18:16</td>\n",
       "      <td>1.314115e+12</td>\n",
       "      <td>Чат / События полученные через AMQP / Отправка...</td>\n",
       "      <td>Иркутская область</td>\n",
       "      <td>Братск</td>\n",
       "      <td>2.662302e+18</td>\n",
       "      <td>Сменный график</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Начинающий специалист</td>\n",
       "      <td>Ответственная ,умею общаться с людьми</td>\n",
       "      <td>Сборщики в магазин</td>\n",
       "      <td>! В гипермаркет требуются сборщики заказов.\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.128231e+12</td>\n",
       "      <td>1.247251e+12</td>\n",
       "      <td>2023-03-13 10:39:39</td>\n",
       "      <td>1.429179e+12</td>\n",
       "      <td>Чат / События полученные через AMQP / Отправка...</td>\n",
       "      <td>Воронежская область</td>\n",
       "      <td>Воронеж</td>\n",
       "      <td>4.597737e+18</td>\n",
       "      <td>Сменный график</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Продавец консультант</td>\n",
       "      <td>Продавец консультант</td>\n",
       "      <td>Сборщики заказов</td>\n",
       "      <td>! В гипермаркет требуются сборщики заказов.\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.528780e+11</td>\n",
       "      <td>1.121617e+12</td>\n",
       "      <td>2023-03-13 01:15:04</td>\n",
       "      <td>1.425790e+12</td>\n",
       "      <td>Чат / События полученные через AMQP / Отправка...</td>\n",
       "      <td>Московская область</td>\n",
       "      <td>Химки</td>\n",
       "      <td>6.790487e+17</td>\n",
       "      <td>Вахтовый метод</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Медсестра на дом капельницы уколы</td>\n",
       "      <td>Я Настя из Таджикистана год рождения 1990 стаж...</td>\n",
       "      <td>Работа вахта на складе 15/15, с проживанием)</td>\n",
       "      <td>! ВАХТА в МОСКОВСКОЙ ОБЛАСТИ !\\n\\nВОЗМОЖНО, БЕ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465633</th>\n",
       "      <td>8.245448e+11</td>\n",
       "      <td>1.427353e+12</td>\n",
       "      <td>2023-03-13 13:45:18</td>\n",
       "      <td>1.423216e+12</td>\n",
       "      <td>Чат / События полученные через AMQP / Отправка...</td>\n",
       "      <td>Москва</td>\n",
       "      <td>Москва</td>\n",
       "      <td>6.613096e+17</td>\n",
       "      <td>Сменный график</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Официантка работа</td>\n",
       "      <td>Ответственная исполнительная пунктуальность</td>\n",
       "      <td>Помощник на обработку документов на 4 часа</td>\n",
       "      <td>Требуется помощник на обработку входящей докум...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465634</th>\n",
       "      <td>1.181303e+12</td>\n",
       "      <td>1.373503e+12</td>\n",
       "      <td>2023-03-13 08:20:30</td>\n",
       "      <td>1.431757e+12</td>\n",
       "      <td>Пользовательские события / Объявления / Просмо...</td>\n",
       "      <td>Псковская область</td>\n",
       "      <td>Великие Луки</td>\n",
       "      <td>3.857741e+18</td>\n",
       "      <td>Сменный график</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Любая работа, подработка</td>\n",
       "      <td>Быстро обучаюсь</td>\n",
       "      <td>Статрший администратор службы приема и размещения</td>\n",
       "      <td>Описание работодателя:\\nОтель 4 звезды,   г. А...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465635</th>\n",
       "      <td>1.127932e+12</td>\n",
       "      <td>1.428407e+12</td>\n",
       "      <td>2023-03-13 19:20:25</td>\n",
       "      <td>1.429851e+12</td>\n",
       "      <td>Чат / События полученные через AMQP / Отправка...</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>1.586361e+18</td>\n",
       "      <td>Вахтовый метод</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Репетитор по английскому языку</td>\n",
       "      <td>стрессоустойчивый и коммуникабельный профессионал</td>\n",
       "      <td>Вахта проживание + питание/Упаковщик/20 смен</td>\n",
       "      <td>Вахта 15 смен с питанием и проживанием - ЗВОНИ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465636</th>\n",
       "      <td>9.636738e+11</td>\n",
       "      <td>1.431304e+12</td>\n",
       "      <td>2023-03-13 13:14:56</td>\n",
       "      <td>1.341265e+12</td>\n",
       "      <td>Пользовательские события / Объявления / Просмо...</td>\n",
       "      <td>Башкортостан</td>\n",
       "      <td>Стерлитамак</td>\n",
       "      <td>5.963610e+18</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Тракторист на мтз 82</td>\n",
       "      <td>ищу работу на своем тракторе мтз 82!</td>\n",
       "      <td>Менеджер по работе с клиентами</td>\n",
       "      <td>Требуется сотрудница в сервисный центр/магазин...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465637</th>\n",
       "      <td>8.994625e+10</td>\n",
       "      <td>1.101459e+12</td>\n",
       "      <td>2023-03-13 22:58:54</td>\n",
       "      <td>1.432198e+12</td>\n",
       "      <td>Чат / События полученные через AMQP / Отправка...</td>\n",
       "      <td>Алтайский край</td>\n",
       "      <td>Бийск</td>\n",
       "      <td>1.074782e+18</td>\n",
       "      <td>Сменный график</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Оператор</td>\n",
       "      <td>Регистратор медси барнаул</td>\n",
       "      <td>Продавец за прилавок. Еженедельные выплаты(Лента)</td>\n",
       "      <td>Мы приглашаем на вакансию: Продавец за прилаво...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462951 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             User_id       Item_id           EventDate  last_resume_id  \\\n",
       "index                                                                    \n",
       "0       1.030430e+12  1.353529e+12 2023-03-13 11:21:22    1.427381e+12   \n",
       "1       8.000233e+11  1.237305e+12 2023-03-13 03:02:08    1.401474e+12   \n",
       "2       1.073960e+12  1.237305e+12 2023-03-13 13:18:16    1.314115e+12   \n",
       "3       1.128231e+12  1.247251e+12 2023-03-13 10:39:39    1.429179e+12   \n",
       "4       6.528780e+11  1.121617e+12 2023-03-13 01:15:04    1.425790e+12   \n",
       "...              ...           ...                 ...             ...   \n",
       "465633  8.245448e+11  1.427353e+12 2023-03-13 13:45:18    1.423216e+12   \n",
       "465634  1.181303e+12  1.373503e+12 2023-03-13 08:20:30    1.431757e+12   \n",
       "465635  1.127932e+12  1.428407e+12 2023-03-13 19:20:25    1.429851e+12   \n",
       "465636  9.636738e+11  1.431304e+12 2023-03-13 13:14:56    1.341265e+12   \n",
       "465637  8.994625e+10  1.101459e+12 2023-03-13 22:58:54    1.432198e+12   \n",
       "\n",
       "                                               event_name  \\\n",
       "index                                                       \n",
       "0       Пользовательские события / Объявления / Просмо...   \n",
       "1       Чат / События полученные через AMQP / Отправка...   \n",
       "2       Чат / События полученные через AMQP / Отправка...   \n",
       "3       Чат / События полученные через AMQP / Отправка...   \n",
       "4       Чат / События полученные через AMQP / Отправка...   \n",
       "...                                                   ...   \n",
       "465633  Чат / События полученные через AMQP / Отправка...   \n",
       "465634  Пользовательские события / Объявления / Просмо...   \n",
       "465635  Чат / События полученные через AMQP / Отправка...   \n",
       "465636  Пользовательские события / Объявления / Просмо...   \n",
       "465637  Чат / События полученные через AMQP / Отправка...   \n",
       "\n",
       "                     Region              City  session_hash   microcat_name  \\\n",
       "index                                                                         \n",
       "0                    Москва            Москва  8.753473e+18     Полный день   \n",
       "1         Иркутская область            Братск  8.963607e+18  Сменный график   \n",
       "2         Иркутская область            Братск  2.662302e+18  Сменный график   \n",
       "3       Воронежская область           Воронеж  4.597737e+18  Сменный график   \n",
       "4        Московская область             Химки  6.790487e+17  Вахтовый метод   \n",
       "...                     ...               ...           ...             ...   \n",
       "465633               Москва            Москва  6.613096e+17  Сменный график   \n",
       "465634    Псковская область      Великие Луки  3.857741e+18  Сменный график   \n",
       "465635            Татарстан  Набережные Челны  1.586361e+18  Вахтовый метод   \n",
       "465636         Башкортостан       Стерлитамак  5.963610e+18     Полный день   \n",
       "465637       Алтайский край             Бийск  1.074782e+18  Сменный график   \n",
       "\n",
       "        Platform_id                          res_title  \\\n",
       "index                                                    \n",
       "0               3.0                         Подработка   \n",
       "1               3.0                  Не имеет значения   \n",
       "2               4.0              Начинающий специалист   \n",
       "3               2.0               Продавец консультант   \n",
       "4               3.0  Медсестра на дом капельницы уколы   \n",
       "...             ...                                ...   \n",
       "465633          3.0                  Официантка работа   \n",
       "465634          3.0           Любая работа, подработка   \n",
       "465635          4.0     Репетитор по английскому языку   \n",
       "465636          3.0               Тракторист на мтз 82   \n",
       "465637          4.0                           Оператор   \n",
       "\n",
       "                                                  res_des  \\\n",
       "index                                                       \n",
       "0       Бригадир раздачи газет на ж/ д станциях, интер...   \n",
       "1                                 Срочно нужна работа !!!   \n",
       "2                   Ответственная ,умею общаться с людьми   \n",
       "3                                    Продавец консультант   \n",
       "4       Я Настя из Таджикистана год рождения 1990 стаж...   \n",
       "...                                                   ...   \n",
       "465633        Ответственная исполнительная пунктуальность   \n",
       "465634                                    Быстро обучаюсь   \n",
       "465635  стрессоустойчивый и коммуникабельный профессионал   \n",
       "465636               ищу работу на своем тракторе мтз 82!   \n",
       "465637                          Регистратор медси барнаул   \n",
       "\n",
       "                                                vac_title  \\\n",
       "index                                                       \n",
       "0                           Диспетчер оператор (менеджер)   \n",
       "1                                      Сборщики в магазин   \n",
       "2                                      Сборщики в магазин   \n",
       "3                                        Сборщики заказов   \n",
       "4            Работа вахта на складе 15/15, с проживанием)   \n",
       "...                                                   ...   \n",
       "465633         Помощник на обработку документов на 4 часа   \n",
       "465634  Статрший администратор службы приема и размещения   \n",
       "465635       Вахта проживание + питание/Упаковщик/20 смен   \n",
       "465636                     Менеджер по работе с клиентами   \n",
       "465637  Продавец за прилавок. Еженедельные выплаты(Лента)   \n",
       "\n",
       "                                                  vac_des  label  rank  \\\n",
       "index                                                                    \n",
       "0       ! ! ! ВНИМАНИЕ ! ! ! ОЧЕНЬ ВАЖНО ! ! ! требуют...      1     1   \n",
       "1       ! В гипермаркет требуются сборщики заказов.\\n\\...      1     1   \n",
       "2       ! В гипермаркет требуются сборщики заказов.\\n\\...      1     2   \n",
       "3       ! В гипермаркет требуются сборщики заказов.\\n\\...      1     1   \n",
       "4       ! ВАХТА в МОСКОВСКОЙ ОБЛАСТИ !\\n\\nВОЗМОЖНО, БЕ...      1     1   \n",
       "...                                                   ...    ...   ...   \n",
       "465633  Требуется помощник на обработку входящей докум...      0     0   \n",
       "465634  Описание работодателя:\\nОтель 4 звезды,   г. А...      0     0   \n",
       "465635  Вахта 15 смен с питанием и проживанием - ЗВОНИ...      0     0   \n",
       "465636  Требуется сотрудница в сервисный центр/магазин...      0     0   \n",
       "465637  Мы приглашаем на вакансию: Продавец за прилаво...      0     0   \n",
       "\n",
       "        max_rank  vac_id  \n",
       "index                     \n",
       "0              1       0  \n",
       "1              2       1  \n",
       "2              2       1  \n",
       "3              1       2  \n",
       "4             21       3  \n",
       "...          ...     ...  \n",
       "465633         0   81055  \n",
       "465634         0   42846  \n",
       "465635         0   92719  \n",
       "465636         0   82627  \n",
       "465637         0   93561  \n",
       "\n",
       "[462951 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('avito_cv2vac_with_ranks_clear.pq')\n",
    "vac_to_id = dict(zip(df['vac_des'].unique(), range(df['vac_des'].nunique())))\n",
    "df['vac_id'] = df['vac_des'].apply(lambda x: vac_to_id[x])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jFX04Lfd9ls"
   },
   "source": [
    "# 2. Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VI6aztI2TmMG"
   },
   "outputs": [],
   "source": [
    "LEN_BERT = 768\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsijgMN9d_SU"
   },
   "source": [
    "# 3. Make SiameseDataset and collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AYmSkRqYWhxd"
   },
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, df, res_title, res_des, vac_title, vac_des, label_column, rank_column, max_rank_column):\n",
    "        \"\"\"\n",
    "         Create dataset for Siamese Net training.\n",
    "\n",
    "         Parameters\n",
    "         ----------\n",
    "         df : pd.DataFrame\n",
    "             the dataframe we create dataset from\n",
    "         vac_embed_column: str\n",
    "             name of the column of the vacancy embeddings\n",
    "         res_embed_column: str\n",
    "             name of the column of the resume embeddings\n",
    "         res_des_column: str\n",
    "             name of the column of the resume text description\n",
    "         label_column: str\n",
    "             name of the column of the vacancy embeddings\n",
    "         rank_column: str\n",
    "             name of the column of the resume rank \n",
    "         max_rank_column: str\n",
    "             name of the column of the max resumes rank for this vacancy \n",
    "        need new desription\n",
    "\n",
    "             Returns\n",
    "         -------\n",
    "         None\n",
    "         \"\"\"\n",
    "        self.df = df[[res_title, res_des, vac_title, vac_des,label_column, rank_column, max_rank_column]]\n",
    "\n",
    "        self.res_title = res_title\n",
    "        self.res_des = res_des\n",
    "        self.vac_title = vac_title\n",
    "        self.vac_des = vac_des\n",
    "        self.label_column = label_column\n",
    "        self.rank_column = rank_column\n",
    "        self.max_rank_column = max_rank_column\n",
    "\n",
    "        # предполагаю, что каждое резюме кидается ровно на 1 вакансию, составляя одну пару\n",
    "        self.nunique_pairs = df[res_des].nunique()\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "         Return total amount of unique pairs: (vac_embed, res_embed).\n",
    "\n",
    "         Parameters\n",
    "         ----------\n",
    "         None\n",
    "\n",
    "         Returns\n",
    "         -------\n",
    "         int\n",
    "             total amount of unique pairs: (vac_embed, res_embed) \n",
    "         \"\"\"\n",
    "        return self.nunique_pairs\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "         Return training object: (vac_embed, res_embed, label, rank, max_rank);\n",
    "         Return rank and max_rank to penalty most appropriate samples more.\n",
    "\n",
    "         Parameters\n",
    "         ----------\n",
    "         idx: int\n",
    "             index of the samples we want to get.\n",
    "\n",
    "         Returns\n",
    "         -------\n",
    "         tuple[torch.tensor]\n",
    "             training object like a tuple: (vac_embed, res_embed, label, rank, max_rank)\n",
    "\n",
    "        '''\n",
    "        demandimg_row = self.df.iloc[idx, :]\n",
    "        \n",
    "        return torch.cat([get_embed(demandimg_row[self.res_title]), get_embed(demandimg_row[self.res_des])], dim=0), \\\n",
    "                torch.cat([get_embed(demandimg_row[self.vac_title]), get_embed(demandimg_row[self.vac_des])],dim=0), \\\n",
    "           torch.tensor(demandimg_row[self.label_column]), torch.tensor(demandimg_row[self.rank_column]), torch.tensor(demandimg_row[self.max_rank_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(data, tf):\n",
    "    answer = []\n",
    "    for item in list(sentenize(data)):\n",
    "            answer.append(tf.transform(item.text).reshape(1,LEN_BERT))\n",
    "    return torch.cat(answer, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0507,  0.0391, -0.5538,  ...,  0.5727,  0.5194, -0.6324],\n",
       "         [-0.1854, -0.0636, -0.7324,  ..., -0.7390,  0.4568, -0.7054],\n",
       "         [ 0.2169, -0.8906, -0.7857,  ..., -0.1507, -0.4306, -0.1799],\n",
       "         [-0.8015, -0.8706, -0.7585,  ...,  0.3070, -0.1467,  0.2445],\n",
       "         [-0.9528, -0.8152, -0.8993,  ..., -0.3896, -0.9953, -0.6194]]),\n",
       " [Substring(0, 11, 'я иду домой')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '''\n",
    "... - \"Так в чем же дело?\" - \"Не ра-ду-ют\".\n",
    "... И т. д. и т. п. В общем, вся газета.\n",
    "... Я пошел домой\n",
    "... '''\n",
    "list(sentenize(text))\n",
    "get_embed(text), list(sentenize(\"я иду домой\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8pDMQhLob8fD"
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"     \n",
    "     Make dict samples from tuples (it is easier to use);\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "       data: is a list of tuples with (vac_embed, res_embed, label, rank, max_rank)\n",
    "      \n",
    "    \"\"\"\n",
    "    res, vac,  label, rank, max_rank = zip(*data)\n",
    "\n",
    "    dict_data = {'res': res, \n",
    "                 'vac': vac,\n",
    "                 'label': label,\n",
    "                 'rank': rank,\n",
    "                 'max_rank': max_rank}\n",
    "\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzTxCaWJeEIC"
   },
   "source": [
    "# 4. Create dataset amd dataloader instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YmeuLlLwYB6f"
   },
   "outputs": [],
   "source": [
    "dataset = SiameseDataset(df, 'res_title', 'res_des', \"vac_title\", \"vac_des\", 'label', 'rank', 'max_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NTIWu4lXcvsc"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"val_id.pickle\", 'rb') as f:\n",
    "    val_id = pickle.load(f)\n",
    "\n",
    "with open(\"test_id.pickle\", 'rb') as f:\n",
    "    test_id = pickle.load(f)\n",
    "\n",
    "with open(\"train_id.pickle\", 'rb') as f:\n",
    "    train_id = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiameseDataset(df[df['vac_id'].isin(train_id)],'res_title', 'res_des', \"vac_title\", \"vac_des\", 'label', 'rank', 'max_rank')\n",
    "\n",
    "val_dataset = SiameseDataset(df[df['vac_id'].isin(val_id)],'res_title', 'res_des', \"vac_title\", \"vac_des\", 'label', 'rank', 'max_rank')\n",
    "\n",
    "test_dataset = SiameseDataset(df[df['vac_id'].isin(test_id)],'res_title', 'res_des', \"vac_title\", \"vac_des\", 'label', 'rank', 'max_rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7kV39kGeHtO"
   },
   "source": [
    "# 5. Get a batch and overview it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2EMu_v-RiJm_"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmP4vX1SiUUz",
    "outputId": "dc0f46af-b5f7-4a59-c513-1f9571e95c00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# батч -- это словарь\n",
    "\n",
    "type(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k78A7aZIdU6p",
    "outputId": "7eb9ef24-d6c2-47a2-911e-439ed4302209"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['res', 'vac', 'label', 'rank', 'max_rank'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# его ключи \n",
    "\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VvCjVTOJdSzz",
    "outputId": "95ade1c9-383e-4e26-e775-22a1c539bb37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# внутри каждого ключа кортеж длиной batch_size\n",
    "\n",
    "type(batch['res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMcBy76VdkHV",
    "outputId": "c82d617a-0d0c-4cab-862d-13b73b926159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " tensor([[-0.5827, -0.6846, -0.5353,  ...,  0.4666,  0.1050, -0.2236],\n",
       "         [-0.6029, -0.2126,  0.2192,  ..., -0.0095,  0.1594, -0.5768],\n",
       "         [-0.2919, -0.1481, -0.8866,  ..., -0.0223,  0.1018, -0.6278],\n",
       "         [-0.4945, -0.1658, -0.6466,  ...,  0.8908, -0.1328, -0.0491],\n",
       "         [-0.3670,  0.1026, -0.1941,  ...,  0.1574, -0.2153, -0.2915],\n",
       "         [-0.5902, -0.5470, -0.1846,  ..., -0.0166,  0.2765,  0.0419]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['res'][0]), batch['res'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mYj1reUdlcB",
    "outputId": "239a17f1-b806-47fa-d3fa-cf8d6900b75e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# каждый элемент уже то, что заявлено в ключах\n",
    "\n",
    "type(batch['vac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6wN9O96dnYD",
    "outputId": "0e74adda-31f5-47ea-b54c-cb50723a0f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 768])\n",
      "torch.Size([19, 768])\n",
      "torch.Size([23, 768])\n",
      "torch.Size([11, 768])\n",
      "torch.Size([19, 768])\n",
      "torch.Size([19, 768])\n",
      "torch.Size([17, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([17, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([10, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([12, 768])\n",
      "torch.Size([15, 768])\n",
      "torch.Size([16, 768])\n",
      "torch.Size([15, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([19, 768])\n",
      "torch.Size([21, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([14, 768])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([20, 768])\n",
      "torch.Size([19, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([21, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([16, 768])\n",
      "torch.Size([30, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([21, 768])\n",
      "torch.Size([15, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([10, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([20, 768])\n",
      "torch.Size([12, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([10, 768])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([10, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([11, 768])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([22, 768])\n",
      "torch.Size([18, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([12, 768])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([23, 768])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([12, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([25, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([12, 768])\n",
      "torch.Size([13, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([14, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([24, 768])\n",
      "torch.Size([17, 768])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([5, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([9, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([14, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([24, 768])\n",
      "torch.Size([11, 768])\n",
      "torch.Size([26, 768])\n",
      "torch.Size([20, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([14, 768])\n",
      "torch.Size([14, 768])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([16, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([12, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([7, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([10, 768])\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "# размерность эмбеддинга\n",
    "for item in batch['vac']:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m74_DPZZdph3"
   },
   "source": [
    "# 6. Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseCVNet(nn.Module):\n",
    "    def __init__(self,  rnn_hidden_dim, \n",
    "               hidden_layers, fc1_output=512, fc2_output=1):\n",
    "    \n",
    "        super(SiameseCVNet, self).__init__()\n",
    "\n",
    "        self.rnn_hidden_dim = rnn_hidden_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "    \n",
    "        self.rnn = nn.LSTM(input_size=LEN_BERT,\n",
    "                           hidden_size=rnn_hidden_dim,\n",
    "                           num_layers=hidden_layers,\n",
    "                           batch_first=True)\n",
    "        # считаем после конкатенации в forward_one\n",
    "        self.fc1_input_one = 2 * (LEN_BERT+(self.hidden_layers + 1) * self.rnn_hidden_dim)\n",
    "\n",
    "        # но мы конкатенируем 2 сэмпла!\n",
    "        self.fc1_input = 2 * self.fc1_input_one\n",
    "\n",
    "        self.fc1_output = fc1_output\n",
    "        self.fc2_output = fc2_output\n",
    "\n",
    "        fc1 = nn.Linear(self.fc1_input, self.fc1_output)\n",
    "        relu = nn.ReLU()\n",
    "        fc2 = nn.Linear(self.fc1_output, self.fc2_output)\n",
    "        sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.nn_head = nn.Sequential(\n",
    "            fc1,\n",
    "            relu,\n",
    "            fc2,\n",
    "            sigmoid\n",
    "\n",
    "          ) \n",
    "\n",
    "    def forward(self, vac_embeds, res_embeds):\n",
    "\n",
    "        catted_output_vac = self.forward_one(vac_embeds)\n",
    "        catted_output_res = self.forward_one(res_embeds)\n",
    "\n",
    "        # конкатенируем и пускаем через dense\n",
    "#         print(catted_output_vac.shape, catted_output_res.shape)\n",
    "        catted_output = torch.cat((catted_output_vac, catted_output_res), dim=-1)\n",
    "#         print(catted_output.shape, self.fc1_input, self.fc1_output)\n",
    "        sigm_output = self.nn_head(catted_output)\n",
    "\n",
    "        return sigm_output\n",
    "\n",
    "    def forward_one(self, batch):\n",
    "        '''\n",
    "        image there is just a tensor of embeddings\n",
    "        shit with dims for sure\n",
    "        '''\n",
    "\n",
    "#         print('sample:', batch.shape)\n",
    "        rnn_output, (hidden_states, cell_states) = self.rnn(batch)\n",
    "\n",
    "        # print('rnn output:', rnn_output.shape)\n",
    "\n",
    "        embed_max_pool = batch.max(dim=1)[0]\n",
    "        embed_avg_pool = batch.sum(dim=1) / len(batch)\n",
    "\n",
    "        rnn_max_pool = rnn_output.max(dim=1)[0]\n",
    "        rnn_avg_pool = rnn_output.sum(dim=1) / len(rnn_output)  \n",
    "\n",
    "        # print('embed pool:', embed_max_pool.shape, embed_avg_pool.shape)\n",
    "        # print('rnn output pool:', rnn_max_pool.shape, rnn_max_pool.shape) \n",
    "        # print('hidden and state: ', hidden_states.shape, cell_states.shape)\n",
    "\n",
    "        # тут 0 ось -- кол-во слоев в rnn-блоке\n",
    "        hidden_states = torch.cat([hidden_states[i, :, :] for i in range(hidden_states.shape[0])], dim=-1)\n",
    "        cell_states = torch.cat([cell_states[i, :, :] for i in range(cell_states.shape[0])], dim=-1)\n",
    "\n",
    "        # print('hidden and state: ', hidden_states.shape, cell_states.shape)\n",
    "\n",
    "        catted_output = torch.cat((embed_max_pool, embed_avg_pool, rnn_max_pool, \n",
    "                                  rnn_avg_pool, hidden_states, cell_states), dim=-1)\n",
    "\n",
    "        return catted_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "    \"rnn_hidden_dim\": 512,\n",
    "    \"hidden_layers\": 1,\n",
    "    \"fc1_output\": 256,\n",
    "    \"fc2_output\": 1,\n",
    "}\n",
    "\n",
    "experement_parameters = {\n",
    "    \"optimizer_lr\": 1e-4,\n",
    "    \"optimizer_weight_decay\": 1e-4,\n",
    "    \"scheduler_patience\": 5,\n",
    "    \"scheduler_factor\": 0.8,\n",
    "    \"dataset_train\": train_dataset,\n",
    "    \"dataset_test\": val_dataset,\n",
    "    \"dataset_val\": test_dataset,\n",
    "    \"batch_size_train\": 64, \n",
    "    \"batch_size_val\": 64, \n",
    "    \"batch_size_test\": 64,\n",
    "    \"num_epochs\": 5,\n",
    "    \"train_shuffle\": True,\n",
    "    \"collate_fn\": collate_fn,\n",
    "    \"verbose_every_n_batches\": 300,\n",
    "    \"eval_on_train\": False,\n",
    "}\n",
    "\n",
    "# model = SiameseCVNet(   \n",
    "#     rnn_hidden_dim=model_parameters[\"rnn_hidden_dim\"],\n",
    "#     hidden_layers=model_parameters[\"hidden_layers\"],\n",
    "#     fc1_output=model_parameters[\"fc1_output\"],\n",
    "#     fc2_output=model_parameters[\"fc2_output\"]\n",
    "# )\n",
    "\n",
    "# optimizer = torch.optim.AdamW(\n",
    "#     params=model.parameters(),\n",
    "#     lr=experement_parameters[\"optimizer_lr\"],\n",
    "#     weight_decay=experement_parameters[\"optimizer_weight_decay\"]\n",
    "# )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer=optimizer,\n",
    "#     patience=experement_parameters[\"scheduler_patience\"],\n",
    "#     factor=experement_parameters[\"scheduler_factor\"]\n",
    "# )\n",
    "loss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SiameseCVNet(   \n",
    "    rnn_hidden_dim=model_parameters[\"rnn_hidden_dim\"],\n",
    "    hidden_layers=model_parameters[\"hidden_layers\"],\n",
    "    fc1_output=model_parameters[\"fc1_output\"],\n",
    "    fc2_output=model_parameters[\"fc2_output\"]\n",
    ")\n",
    "model_state_dict = torch.load(\"model.pt\")\n",
    "model.load_state_dict(model_state_dict)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=experement_parameters[\"optimizer_lr\"],\n",
    "    weight_decay=experement_parameters[\"optimizer_weight_decay\"]\n",
    ")\n",
    "optimizer.load_state_dict(torch.load(\"optimizer.pt\"))\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    patience=experement_parameters[\"scheduler_patience\"],\n",
    "    factor=experement_parameters[\"scheduler_factor\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_tuple_to_tensor(tensors):\n",
    "    ns = list([tensor.shape[0] for tensor in tensors])\n",
    "    tensor_list = [torch.randn(n, LEN_BERT) for n in ns]\n",
    "\n",
    "    # определяем максимальную размерность\n",
    "    max_size = max(ns)\n",
    "\n",
    "    # добавляем нулевые строки к тензорам, чтобы они имели одинаковую размерность\n",
    "    for i, elem in enumerate(tensors):\n",
    "        if tensor_list[i].shape[0] < max_size:\n",
    "            tensor_list[i] = torch.cat((elem, torch.zeros(max_size-tensor_list[i].shape[0], LEN_BERT)), dim=0)\n",
    "\n",
    "    # объединяем тензоры по первой размерности\n",
    "    return  torch.cat([tensor.unsqueeze(0) for tensor in tensor_list], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, dataset, batch_size, shuffle, collate_fn, \n",
    "                verbose_every_n_batches=300):\n",
    "    \n",
    "    torch_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "    loss = torch.nn.BCELoss()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_batches = 1\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    model.train()\n",
    "    for batch in torch_dataloader:   \n",
    "        vac, res, true = batch[\"vac\"], batch[\"res\"], batch[\"label\"]\n",
    "        vac = convert_tuple_to_tensor(vac)\n",
    "        res = convert_tuple_to_tensor(res)\n",
    "        pred = torch.flatten(model(vac.to(DEVICE), res.to(DEVICE)).float())\n",
    "        true = torch.stack(list([elem for elem in true]), dim=0).to(DEVICE).float()\n",
    "        batch_loss = loss(pred, true)\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_train_loss += batch_loss * batch_size\n",
    "        \n",
    "        if num_batches == 1:\n",
    "            print(f\"Train loss after first batch: {total_train_loss}\", end='\\r')    \n",
    "        \n",
    "        if num_batches % verbose_every_n_batches == 0:\n",
    "            print(f\"Mean train loss on the last {verbose_every_n_batches} batches: {total_train_loss / verbose_every_n_batches};\", end=\"\\r\")\n",
    "            \n",
    "        num_batches += 1\n",
    "            \n",
    "    print(f\"Mean train loss after epoch: {total_train_loss / num_batches}\")\n",
    "    print(f\"Total train loss after epoch: {total_train_loss}\")\n",
    "      \n",
    "\n",
    "\n",
    "def eval_model(model, dataset, batch_size, collate_fn, \n",
    "               verbose_every_n_batches=300):\n",
    "    torch_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    preds, targets = [], []\n",
    "    total_valid_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in torch_dataloader:\n",
    "            vac, res, true = batch[\"vac\"], batch[\"res\"], batch[\"label\"]\n",
    "            vac = convert_tuple_to_tensor(vac)\n",
    "            res = convert_tuple_to_tensor(res)\n",
    "            pred = torch.flatten(model(vac.to(DEVICE), res.to(DEVICE)).float())\n",
    "            true = torch.stack(list([elem for elem in true]), dim=0).to(DEVICE).float()\n",
    "            preds.extend(pred.detach().cpu().numpy())\n",
    "            targets.extend(true)\n",
    "    return targets, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_cuda_cache():\n",
    "    start_available, reserved = torch.cuda.mem_get_info()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    fin_available, reserved = torch.cuda.mem_get_info()\n",
    "    print(f\"cleaned {(fin_available - start_available) / 2**10} gb\")\n",
    "    print(f\"available {fin_available / 2**10} gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_loop(\n",
    "    model, optimizer, scheduler, \n",
    "    dataset_train, dataset_val, dataset_test,\n",
    "    batch_size_train, batch_size_test, batch_size_val,\n",
    "    num_epochs, train_shuffle, collate_fn, \n",
    "    verbose_every_n_batches, eval_on_train, \n",
    "    early_stopping_patience=7\n",
    "):\n",
    "    with open(\"logs_lstm.txt\", 'w') as f:\n",
    "        pass\n",
    "    model = model.to(DEVICE)\n",
    "    for n_epoch in tqdm(range(1, num_epochs + 1), desc=\"nums\"):\n",
    "        train_epoch(\\\n",
    "                    model=model, \\\n",
    "                    optimizer=optimizer, \\\n",
    "                    dataset=dataset_train, \\\n",
    "                    batch_size=batch_size_train, \\\n",
    "                    shuffle=train_shuffle, \\\n",
    "                    collate_fn=collate_fn, \\\n",
    "                    verbose_every_n_batches=verbose_every_n_batches\n",
    "                  )\n",
    "                    \n",
    "        # clean cache before validation    \n",
    "        clean_cuda_cache()     \n",
    "        targets_val, preds_val = eval_model(\n",
    "            model=model,\n",
    "            dataset=dataset_val,\n",
    "            batch_size=batch_size_val,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        # for logging while validating\n",
    "        loss = torch.nn.BCELoss()\n",
    "        # count common loss\n",
    "        val_loss = loss(torch.tensor(preds_val).float(),torch.tensor(targets_val).float())\n",
    "        \n",
    "        with open(\"logs_lstm.txt\", 'a') as f:\n",
    "            f.write(f'epoch {n_epoch}. valid loss: {val_loss}\\n')\n",
    "\n",
    "        # torch.save(model.state_dict(), os.path.join(EXP_CHECKPOINTS_PATH, f\"epoch_{n_epoch}_{datetime.now().strftime('%Y-%m-%d')}_{datetime.now().strftime('%H:%M:%S')}_testCC_{round(test_roc_auc_CC, 3)}_testPIL_{round(test_roc_auc_PIL, 3)}.pt\"))             \n",
    "        targets_test, preds_test = eval_model(\n",
    "            model=model,\n",
    "            dataset=dataset_test,\n",
    "            batch_size=batch_size_test,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        \n",
    "        # count common loss\n",
    "        test_loss = loss(torch.tensor(preds_test).float(), torch.tensor(targets_test).float())\n",
    "        scheduler.step(val_loss)\n",
    "        if eval_on_train:\n",
    "                targets_train, preds_train = eval_model(\n",
    "                model=model,\n",
    "                dataset=dataset_train,\n",
    "                batch_size=batch_size_train,\n",
    "                collate_fn=collate_fn\n",
    "            )\n",
    "            \n",
    "                # count common loss\n",
    "                train_loss = loss(torch.tensor(targets_train), torch.tensor(preds_train))\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "nums:   0%|                                                                                      | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train loss after epoch: 0.2445689737796783440601158142;\n",
      "Total train loss after epoch: 233.07424926757812\n",
      "cleaned 270336.0 gb\n",
      "available 3202048.0 gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "nums:  20%|██████████████▍                                                         | 1/5 [1:52:26<7:29:44, 6746.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train loss after epoch: 1.2201545587231521e-06505007e-06;;;\n",
      "Total train loss after epoch: 0.001162807340733707\n",
      "cleaned 339968.0 gb\n",
      "available 3212288.0 gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "nums:  40%|████████████████████████████▊                                           | 2/5 [3:45:24<5:38:14, 6764.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train loss after epoch: 1.204613226946094e-07498051053e-07;\n",
      "Total train loss after epoch: 0.0001147996517829597\n",
      "cleaned 329728.0 gb\n",
      "available 3212288.0 gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "nums:  60%|███████████████████████████████████████████▏                            | 3/5 [5:38:17<3:45:37, 6768.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train loss after epoch: 5.30376880192307e-081359567556e-07;\n",
      "Total train loss after epoch: 5.0544920668471605e-05\n",
      "cleaned 327680.0 gb\n",
      "available 3212288.0 gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "nums:  80%|█████████████████████████████████████████████████████████▌              | 4/5 [7:31:17<1:52:53, 6773.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean train loss after epoch: 1.8451861194535013e-070998164e-07;\n",
      "Total train loss after epoch: 0.0001758462458383292\n",
      "cleaned 327680.0 gb\n",
      "available 3212288.0 gb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nums: 100%|██████████████████████████████████████████████████████████████████████████| 5/5 [9:24:18<00:00, 6771.75s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_val_loop(\n",
    "  model=model, optimizer=optimizer, scheduler=scheduler, \n",
    "  dataset_train=experement_parameters[\"dataset_train\"], \n",
    "  dataset_test=experement_parameters[\"dataset_test\"], \n",
    "  dataset_val=experement_parameters[\"dataset_val\"],\n",
    "  batch_size_train=experement_parameters[\"batch_size_train\"],\n",
    "  batch_size_val=experement_parameters[\"batch_size_val\"], \n",
    "  batch_size_test=experement_parameters[\"batch_size_test\"],\n",
    "  num_epochs=experement_parameters[\"num_epochs\"], \n",
    "  train_shuffle=experement_parameters[\"train_shuffle\"], \n",
    "  collate_fn=experement_parameters[\"collate_fn\"], \n",
    "  verbose_every_n_batches=experement_parameters[\"verbose_every_n_batches\"],\n",
    "  eval_on_train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(optimizer.state_dict(), 'optimizer.pt')\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned 274432.0 gb\n",
      "available 3214336.0 gb\n"
     ]
    }
   ],
   "source": [
    "clean_cuda_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference_one_vac(model, dataset, vac_text):\n",
    "    '''\n",
    "      Инференс на 1 вакансии. У вас функция будет отличаться, очевидно\n",
    "    '''\n",
    "    location = dataset[dataset['vac_des'] == vac_text]['City'].iloc[0]\n",
    "    cluster = dataset[(dataset[\"City\"] == location) | \\\n",
    "                    (dataset[\"microcat_name\"] ==\"Удаленная работа\") | \\\n",
    "                    (dataset['microcat_name'] == 'Вахтовый метод')]\n",
    "    vac_title =  cluster[cluster['vac_des'] == vac_text]['vac_title'].iloc[0]\n",
    "    similarities = []\n",
    "    for res_text in cluster['res_des']:\n",
    "        if res_text:\n",
    "            vacc = torch.cat([get_embed(cluster[cluster['res_des'] == res_text]['res_title'].iloc[0]),\\\n",
    "                              get_embed(res_text)], dim=0).to(DEVICE)\n",
    "            ress = torch.cat([get_embed(cluster[cluster['vac_des'] == vac_text]['vac_title'].iloc[0]), \\\n",
    "                              get_embed(vac_text)], dim=0).to(DEVICE)\n",
    "            padd = convert_tuple_to_tensor1((vacc, ress))\n",
    "            similarity = model(padd[0].unsqueeze(0).to(DEVICE), padd[1].unsqueeze(0).to(DEVICE))\n",
    "            similarities.append(similarity.item())\n",
    "        else:\n",
    "            similarities.append(-1)\n",
    "    return similarities, np.arange(cluster.shape[0])\n",
    "\n",
    "def model_inference_dataset(model, dataset):\n",
    "    '''\n",
    "      Инференс на всех вакансиях в dataset\n",
    "    '''\n",
    "    preds = np.zeros((dataset.shape[0]))\n",
    "    for vac in dataset['vac_des'].unique():\n",
    "        model_pred, pred_ind = model_inference_one_vac(model, dataset, vac)\n",
    "        preds[pred_ind] = model_pred\n",
    "\n",
    "    return preds\n",
    "def convert_tuple_to_tensor1(tensors):\n",
    "    ns = list([tensor.shape[0] for tensor in tensors])\n",
    "    tensor_list = [torch.randn(n, LEN_BERT).to(DEVICE) for n in ns]\n",
    "\n",
    "    # определяем максимальную размерность\n",
    "    max_size = max(ns)\n",
    "\n",
    "    # добавляем нулевые строки к тензорам, чтобы они имели одинаковую размерность\n",
    "    for i, elem in enumerate(tensors):\n",
    "        tensor_list[i].to(DEVICE)\n",
    "        if tensor_list[i].shape[0] < max_size:\n",
    "            tensor_list[i] = torch.cat((elem, torch.zeros(max_size-tensor_list[i].shape[0], LEN_BERT).to(DEVICE)), dim=0)\n",
    "\n",
    "    # объединяем тензоры по первой размерности\n",
    "    return  torch.cat([tensor.unsqueeze(0).to(DEVICE) for tensor in tensor_list], dim=0).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseCVNet(\n",
       "  (rnn): LSTM(768, 512, batch_first=True)\n",
       "  (nn_head): Sequential(\n",
       "    (0): Linear(in_features=7168, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def count_ndcg_for_all_resumes(model, df, k=None):\n",
    "    '''\n",
    "  ранжируем к вакансии вообще все резюме из кластера \n",
    "  это походит на боевые условия, но имхо, ждать тут высокого ndcg не стоит из-за разреженнности векторов\n",
    "    '''\n",
    "    if not k:\n",
    "        k = df.shape[0]\n",
    "\n",
    "    df = df.drop_duplicates(['vac_des', 'res_des'])\n",
    "    df.index = range(df.shape[0])\n",
    "    if df.shape[0] > 0:\n",
    "        ndcg_vals = []\n",
    "        for vac in tqdm(df['vac_des'].unique()):\n",
    "            possible_res = df[df['vac_des'] == vac][['res_des', 'rank']]\n",
    "            if possible_res.shape[0] < 3:\n",
    "                continue\n",
    "\n",
    "            true_rank_vector = np.zeros((df.shape[0]))\n",
    "            true_rank_vector[possible_res.index] = possible_res['rank']\n",
    "\n",
    "            model_preds = model_inference_dataset(model, df)\n",
    "\n",
    "            if len(true_rank_vector) < k:\n",
    "                ndcg_vals.append(ndcg_score([true_rank_vector], [model_preds]))\n",
    "            else:\n",
    "                ndcg_vals.append(ndcg_score([true_rank_vector[:k]], [model_preds[:k]]))\n",
    "\n",
    "    return ndcg_vals\n",
    "  \n",
    "def count_ndcg_for_appropriate_resumes(model, df, k=None):\n",
    "    '''\n",
    "  ранжируем только подходящие к вакансии резюме\n",
    "  то есть делаем предикт только для них и смотрим, как алгоритм умеет сортировать \"хорошие\" сэмпл\n",
    "    '''\n",
    "    if not k:\n",
    "        k = float('inf')\n",
    "\n",
    "    df = df.drop_duplicates(['vac_des', 'res_des'])\n",
    "    df.index = range(df.shape[0])\n",
    "    if df.shape[0] > 0:\n",
    "        ndcg_vals = []\n",
    "        for vac in tqdm(df['vac_des'].unique()):\n",
    "            possible_res = df[df['vac_des'] == vac][['City', 'microcat_name', 'vac_des','vac_title','res_title', 'res_des', 'rank']]\n",
    "            if possible_res.shape[0] < 3:\n",
    "                continue\n",
    "\n",
    "            true_rank_vector = possible_res['rank'].values\n",
    "            model_probs = model_inference_dataset(model, possible_res)\n",
    "\n",
    "            if len(true_rank_vector) < k:\n",
    "                ndcg_vals.append(ndcg_score([true_rank_vector], [model_probs]))\n",
    "            else:\n",
    "                ndcg_vals.append(ndcg_score([true_rank_vector[:k]], [model_probs[:k]]))\n",
    "\n",
    "    return ndcg_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mod = count_ndcg_for_appropriate_resumes(model, df.iloc[val_id], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1_input_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7168"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (0+768+(1 + 1) * 512)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0 torch.Size([2048, 768])\n",
      "rnn.weight_hh_l0 torch.Size([2048, 512])\n",
      "rnn.bias_ih_l0 torch.Size([2048])\n",
      "rnn.bias_hh_l0 torch.Size([2048])\n",
      "nn_head.0.weight torch.Size([256, 7168])\n",
      "nn_head.0.bias torch.Size([256])\n",
      "nn_head.2.weight torch.Size([128, 256])\n",
      "nn_head.2.bias torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8291703082115134"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mod)/len(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11139/11139 [03:13<00:00, 57.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666537535464872"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = count_ndcg_for_appropriate_resumes(model, df.iloc[test_id], k=10)\n",
    "sum(test)/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3043d1795ba4e0c21ad8f92575aa91bd2aeb4e429e5ce129ef86fd0e27798542"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
